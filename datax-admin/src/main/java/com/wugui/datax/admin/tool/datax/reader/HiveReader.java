package com.wugui.datax.admin.tool.datax.reader;

import com.google.common.collect.Maps;
import com.wugui.datax.admin.tool.pojo.DataxHivePojo;

import java.util.Map;

/**
 * hive reader 构建类
 *
 * @author jingwk
 * @version 2.0
 * @since 2020/01/05
 */
public class HiveReader extends BaseReaderPlugin implements DataxReaderInterface {
    @Override
    public String getName() {
        return "hdfsreader";
    }

    @Override
    public Map<String, Object> sample() {
        return null;
    }


    @Override
    public Map<String, Object> buildHive(DataxHivePojo plugin) {
        //构建
        Map<String, Object> readerObj = Maps.newLinkedHashMap();
        readerObj.put("name", getName());
        Map<String, Object> parameterObj = Maps.newLinkedHashMap();
        parameterObj.put("path", plugin.getReaderPath());
        parameterObj.put("defaultFS", plugin.getReaderDefaultFS());
        parameterObj.put("fileType", plugin.getReaderFileType());
        parameterObj.put("fieldDelimiter", plugin.getReaderFieldDelimiter());
        parameterObj.put("column", plugin.getColumns());
        if (Boolean.parseBoolean(plugin.getHaveKerberos())) {
            parameterObj.put("haveKerberos",plugin.getHaveKerberos());
//            parameterObj.setKerberosKeytabFilePath(plugin.getKerberosKeytabFilePath());
            parameterObj.put("kerberosKeytabFilePath",plugin.getKerberosKeytabFilePath());
//            parameterObj.setKerberosPrincipal(plugin.getKerberosPrincipal());
            parameterObj.put("kerberosPrincipal",plugin.getKerberosPrincipal());
        }
        readerObj.put("parameter", parameterObj);
        return readerObj;
    }
}
